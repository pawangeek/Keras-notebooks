{"cells":[{"metadata":{},"cell_type":"markdown","source":"## How to Develop Deep Learning Models With Keras"},{"metadata":{},"cell_type":"markdown","source":"1. Define Network.\n2. Compile Network.\n3. Fit Network.\n4. Evaluate Network.\n5. Make Predictions"},{"metadata":{},"cell_type":"markdown","source":"### Define network\n<p>Neural network define in keras as sequence of layers (container-sequential)\n    1. Create instance of sequential class\n    2. create your layers and add them in order that they should be connected"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(2)) # dense layer with two neurons","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Ist layers defines the no. of inputs\n2. For mlp no. of inputs given by input_dim"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential() #instance\nmodel.add(Dense(5,input_dim=2)) #5 neurons in hidden layer, 2 input in visible layer\nmodel.add(Dense(1)) # 1 neuron in output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\n# from [2+1(bias) * 5] = 15 in ist dense layer\n# from [5+1 * 1] in 2 nd dense layer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sequential model are pipelines - Data at top and output at bottom<p> Activation\nfunctions that transform a summed signal from each neuron in a layer can be extracted and\nadded to the Sequential as a layer-like object called the Activation class.**\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(5,input_dim=2))\nmodel.add(Activation('relu'))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n#The choice of activation function is most important for the output layer as it will define the format that predictions will take.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Activation Functions\n<p> Their main purpose is to convert a input signal of a node in a neural network to an output signal<br><br>\n    That output signal now is used as a input in the next layer in the stack."},{"metadata":{},"cell_type":"markdown","source":"## Compile Network\n<p> compiling network transforms the simple sequence of layers that we defined into a highly efficient series of matrix\ntransforms<br>It is always required\nafter defining a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='sgd', loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The type of predictive modeling problem imposes constraints on the type of loss function that can be used.\n* Regression: Mean Squared Error or **mean squared error**.\n* Binary Classification (2 class): Logarithmic Loss, also called cross entropy or **binary crossentropy**.\n* Multiclass Classification (>2 class): Multiclass Logarithmic Loss or **categorical crossentropy**.\n"},{"metadata":{},"cell_type":"markdown","source":"* **Stochastic Gradient Descent**, or sgd, that requires the tuning of a learning rate and momentum.\n* **Adam**, or adam, that requires the tuning of learning rate.\n* **RMSprop**, or rmsprop, that requires the tuning of learning rate.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Finally, you can also specify metrics to collect while fitting your model in addition to then loss function. Generallyt\n2. The most useful additional metric to collect is accuracy for classification problems. \n3. The metrics to collect are specified by name in an array"},{"metadata":{},"cell_type":"markdown","source":"## Fit network\n<p> Fit means adapt the weights on a training dataset"},{"metadata":{},"cell_type":"markdown","source":"* Fitting the network requires the training data to be specified, both a matrix of input patterns, X, and an array of matching output patterns, y\n\n* Batch Size - It is also an efficiency optimization, ensuring that not too many input patterns are loaded into memory at a time\n* This defines the number of patterns that the network is exposed to before the weights are updated within an epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"#history = model.fit(X, y, batch_size=10, epochs=100)","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Once fit, a history object is returned that provides a summary of the performance of the model during training. \n* This includes both the loss and any additional metrics specified when compiling the model, recorded each epoch"},{"metadata":{},"cell_type":"markdown","source":"By default, a progress bar is displayed on the command line for each epoch. You can turn off all output by setting verbose to 0 or reduce them by setting verbose to 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#history = model.fit(X, y, batch_size=10, epochs=100, verbose=0)","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's understand all this by an simple example\n<p> Here, we use Keras to define a network that recognizes MNIST handwritten digits. We start\nwith a very simple neural network and then progressively improve it."},{"metadata":{},"cell_type":"markdown","source":"### Evaluate Network\n\n<p> We can evaluate the performance of the network on a separate dataset, unseen during testing."},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss, accuracy = model.evaluate(X, y)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model evaluates the loss across all of the test patterns, as well as any other metrics specified when the model was compiled, like classification accuracy"},{"metadata":{},"cell_type":"markdown","source":"### Make Predictions\n\n* Once we are satisfied with the performance of our fit model, we can use it to make predictions on new data. \n* This is as easy as calling the **predict()** function on the model with an array of new input patterns."},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = model.predict(X)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predictions will be returned in the format provided by the output layer of the network.\n\n* For a binary classification problem, the predictions may be an array of probabilities for the first class that can be converted to a 1 or 0 by rounding.\n* For a multiclass classification problem, the results may be in the form of an array of probabilities (use argmax() Function)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"otherwise we can use the **predict classes()** function that will automatically convert predictions to integer class values."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}